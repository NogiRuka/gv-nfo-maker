"""Trance Video NFOç”Ÿæˆå™¨ã€‚

ä¸“é—¨ç”¨äºTrance Videoç½‘ç«™çš„æˆäººè§†é¢‘NFOæ–‡ä»¶ç”Ÿæˆã€‚
"""

import re
from typing import Optional
from bs4 import BeautifulSoup
from datetime import datetime

from ..core.base_generator import BaseNfoGenerator
from ..core.movie_data import MovieData
from ..core.exceptions import ScrapingError, NetworkError


class TranceMusicNfoGenerator(BaseNfoGenerator):
    """Trance Videoç½‘ç«™çš„NFOç”Ÿæˆå™¨ã€‚
    
    æ”¯æŒä»Trance Videoç½‘ç«™çˆ¬å–æˆäººè§†é¢‘ä¿¡æ¯å¹¶ç”Ÿæˆæ ‡å‡†NFOæ–‡ä»¶ã€‚
    ä½¿ç”¨æˆäººå†…å®¹ä¸“ç”¨æ¨¡æ¿ã€‚
    """
    
    @property
    def site_name(self) -> str:
        """è¿”å›æ”¯æŒçš„ç½‘ç«™åç§°ã€‚"""
        return "Trance-Video"
    
    @property
    def site_domain(self) -> str:
        """è¿”å›æ”¯æŒçš„ç½‘ç«™åŸŸåã€‚"""
        return "trance-video.com"
    
    def extract_product_id(self, url: str) -> Optional[str]:
        """ä»Trance Video URLä¸­æå–äº§å“IDã€‚
        
        Args:
            url: è§†é¢‘URL
            
        Returns:
            æ‰¾åˆ°åˆ™è¿”å›äº§å“IDï¼Œå¦åˆ™è¿”å›None
            
        æ”¯æŒçš„URLæ ¼å¼ï¼š
        - https://www.trance-video.com/product/detail/39661
        - https://www.trance-video.com/39661
        """
        # æ”¯æŒtrance-video.com URLæ¨¡å¼
        patterns = [
            r"/product/detail/(\d+)",
            r"/(\d+)/?$"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        
        return None
    
    def scrape_movie_info(self, url: str) -> bool:
        """ä»Trance Video URLçˆ¬å–è§†é¢‘ä¿¡æ¯ã€‚
        
        Args:
            url: è§†é¢‘URL
            
        Returns:
            æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
            
        Raises:
            ScrapingError: çˆ¬å–å¤±è´¥æ—¶æŠ›å‡º
            NetworkError: ç½‘ç»œè¯·æ±‚å¤±è´¥æ—¶æŠ›å‡º
        """
        print("ğŸš€ å¼€å§‹å°è¯•è·å–è§†é¢‘ä¿¡æ¯...")
        
        try:
            response = self.make_request(url)
            response.encoding = "utf-8"
            soup = BeautifulSoup(response.text, "html.parser")
            
            # Extract basic information
            title = self._extract_title(soup)
            work_id = self._extract_work_id(soup)
            
            # Combine work ID with title
            if work_id:
                title = f"[{work_id}] {title}".strip()
            
            # åˆå§‹åŒ–ç”µå½±æ•°æ®
            self.movie_data = MovieData(
                title=title,
                original_title=title,
                product_id=self.extract_product_id(url) or "unknown",
                year=self._extract_year(soup),
                plot=self._extract_description(soup),
                outline="",  # æ¦‚è¦é»˜è®¤ç©º
                genres=self._extract_genres(soup),
                runtime=self._extract_duration(soup),
                studio=self._extract_label(soup) or self.site_name,
                release_date=self._extract_release_date(soup),
                poster=self._extract_artwork(soup),  # å°é¢å›¾ç‰‡URL
                maker=self._extract_maker(soup),
                label=self._extract_label(soup) or self.site_name,
                series_name=self._extract_series(soup),
                imdb_id=f"GV-{self.extract_product_id(url) or 'unknown'}"
            )
            
            # æ·»åŠ æ¼”å‘˜ä¿¡æ¯
            performers = self._extract_performers(soup)
            for performer_name in performers:
                self.movie_data.add_actor(performer_name, "Actor")
            
            # æ·»åŠ æ ‡ç­¾ï¼ˆç¬¬ä¸€ä¸ªä¸ºimdbidï¼‰
            self.movie_data.tags.extend([
                self.movie_data.imdb_id,
                "æˆäººè§†é¢‘",
                "æ—¥æœ¬",
                "GV"
            ])
            
            # è®¾ç½®æˆäººè§†é¢‘ç‰¹æœ‰å±æ€§
            self.movie_data.mpaa = "XXX"
            self.movie_data.custom_rating = "XXX"
            
            # ä½¿ç”¨æˆäººæ¨¡æ¿
            self.nfo_template = "adult"
            
            print("âœ… è§†é¢‘ä¿¡æ¯è·å–å®Œæˆ")
            return True
            
        except NetworkError:
            raise
        except Exception as e:
            raise ScrapingError(f"çˆ¬å–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
    
    def _extract_title(self, soup: BeautifulSoup) -> str:
        """ä»é¡µé¢æå–è§†é¢‘æ ‡é¢˜ã€‚
        
        å¯è®¾ç½®çš„å€¼ï¼š
        - æˆäººè§†é¢‘æ ‡é¢˜
        - æ”¯æŒæ—¥æ–‡ã€ä¸­æ–‡ã€è‹±æ–‡æ ‡é¢˜
        - è‡ªåŠ¨æ¸…ç†ç½‘ç«™åç§°ç­‰æ— å…³ä¿¡æ¯
        """
        # å°è¯•å¤šä¸ªé€‰æ‹©å™¨ç”¨äºtrance-video.com
        selectors = [
            "h1",
            ".title",
            "title"
        ]
        
        for selector in selectors:
            title_elem = soup.select_one(selector)
            if title_elem:
                title = title_elem.get_text().strip()
                # æ¸…ç†æ ‡é¢˜ï¼ˆç§»é™¤ç½‘ç«™åç§°ç­‰ï¼‰
                title = re.sub(r'\s*-\s*.*?(trance|video|market).*$', '', title, flags=re.IGNORECASE)
                if title:
                    return title
        
        return "æœªçŸ¥è§†é¢‘æ ‡é¢˜"
    
    def _extract_work_id(self, soup: BeautifulSoup) -> str:
        """ä»é¡µé¢æå–ä½œå“IDã€‚
        
        å¯è®¾ç½®çš„å€¼ï¼š
        - GV-RML4001 æ ¼å¼çš„ä½œå“ID
        - å…¶ä»–è‡ªå®šä¹‰æ ¼å¼çš„ä½œå“ç¼–å·
        """
        # åœ¨é¡µé¢ä¸­æŸ¥æ‰¾ä½œå“ID
        work_id_selectors = [
            ".work-id",
            "[class*='work']",
            "[class*='id']"
        ]
        
        for selector in work_id_selectors:
            id_elem = soup.select_one(selector)
            if id_elem:
                return id_elem.get_text().strip()
        
        # å°è¯•ä»æ–‡æœ¬å†…å®¹ä¸­æå–
        text_content = soup.get_text()
        id_match = re.search(r'([A-Z]{2}-\d{2}-\d{4}-\d{2})', text_content)
        if id_match:
            return id_match.group(1)
        
        return ""
    
    def _extract_performers(self, soup: BeautifulSoup) -> list:
        """ä»é¡µé¢æå–å‡ºæ¼”è€…ä¿¡æ¯ã€‚
        
        æ¼”å‘˜å§“åå¯è®¾ç½®çš„å€¼ï¼š
        - æ—¥æ–‡å§“åï¼ˆå¦‚ï¼šè—¤åŸé“äººã€ç”°å£æ™ƒæ±°ï¼‰
        - ä¸­æ–‡å§“å
        - è‹±æ–‡å§“å
        - è‰ºåæˆ–æ˜µç§°
        - æˆäººè§†é¢‘æ¼”å‘˜å
        """
        performers = []
        
        # æŸ¥æ‰¾å‡ºæ¼”è€…ä¿¡æ¯
        performer_selectors = [
            ".performer",
            ".actor",
            ".cast",
            "[class*='performer']",
            "[class*='actor']"
        ]
        
        for selector in performer_selectors:
            performer_elems = soup.select(selector)
            for elem in performer_elems:
                performer_name = elem.get_text().strip()
                if performer_name and performer_name not in performers:
                    performers.append(performer_name)
        
        return performers if performers else ["æœªçŸ¥å‡ºæ¼”è€…"]
    
    def _extract_genres(self, soup: BeautifulSoup) -> list:
        """ä»é¡µé¢æå–è§†é¢‘ç±»å‹ã€‚
        
        å¯è®¾ç½®çš„å€¼ï¼š
        - GV (é»˜è®¤ï¼Œå¿…é¡»åŒ…å«)
        - ã‚²ã‚¤AV (åŒæ€§æ‹æˆäººè§†é¢‘)
        - ãƒªãƒ¼ãƒãƒ³ã‚‚ã® (ä¸Šç­æ—é¢˜æ)
        - ç­‹è‚‰ç³» (è‚Œè‚‰ç³»)
        - ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ç³» (å‰§æƒ…ç³»)
        - æˆäººã€æ—¥æœ¬ç­‰åœ°åŒºæ ‡ç­¾
        """
        genres = []
        
        # æŸ¥æ‰¾åˆ†ç±»æ ‡ç­¾
        genre_selectors = [
            ".category",
            ".genre",
            ".tag",
            "[class*='category']",
            "[class*='genre']"
        ]
        
        for selector in genre_selectors:
            genre_elems = soup.select(selector)
            for elem in genre_elems:
                genre = elem.get_text().strip()
                if genre and genre not in genres:
                    genres.append(genre)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not genres:
            genres = ["GV", "æˆäºº", "æ—¥æœ¬"]
        
        return genres
    
    def _extract_year(self, soup: BeautifulSoup) -> str:
        """ä»é¡µé¢æå–å‘å¸ƒå¹´ä»½ã€‚
        
        ä»å‘å¸ƒæ—¥æœŸè‡ªåŠ¨è§£æï¼Œæ ¼å¼ï¼šYYYY
        """
        release_date = self._extract_release_date(soup)
        if release_date:
            return release_date.split("-")[0]
        return str(datetime.now().year)
    
    def _extract_description(self, soup: BeautifulSoup) -> str:
        """ä»é¡µé¢æå–è§†é¢‘æè¿°ã€‚
        
        å¯è®¾ç½®çš„å†…å®¹ï¼š
        - è¯¦ç»†çš„å‰§æƒ…æè¿°
        - æˆäººè§†é¢‘å†…å®¹æè¿°
        - æ”¯æŒå¤šè¡Œæ–‡æœ¬å’Œæ¢è¡Œ
        - æ”¯æŒæ—¥æ–‡ã€ä¸­æ–‡ã€è‹±æ–‡ç­‰å¤šè¯­è¨€
        - CDATAæ ¼å¼è¾“å‡º
        """
        desc_selectors = [
            ".description",
            ".summary",
            ".content",
            "[class*='desc']",
            "p"
        ]
        
        for selector in desc_selectors:
            desc_elem = soup.select_one(selector)
            if desc_elem:
                desc_text = desc_elem.get_text().strip()
                if len(desc_text) > 20:  # ç¡®ä¿å†…å®¹å……å®
                    return desc_text
        
        return "ç²¾å½©çš„æˆäººè§†é¢‘ä½œå“ã€‚"
    
    def _extract_release_date(self, soup: BeautifulSoup) -> str:
        """ä»é¡µé¢æå–å‘å¸ƒæ—¥æœŸã€‚
        
        æ ¼å¼ï¼šYYYY-MM-DD
        ç”¨äºreleasedateå’Œpremieredå­—æ®µ
        """
        date_selectors = [
            ".release-date",
            ".date",
            ".published",
            "[class*='date']",
            "time"
        ]
        
        for selector in date_selectors:
            date_elem = soup.select_one(selector)
            if date_elem:
                date_text = date_elem.get_text().strip()
                # å°è¯•è§£æå„ç§æ—¥æœŸæ ¼å¼
                date_patterns = [
                    r"(\d{4})-(\d{2})-(\d{2})",
                    r"(\d{4})\.(\d{2})\.(\d{2})",
                    r"(\d{2})/(\d{2})/(\d{4})",
                    r"(\d{4})"
                ]
                
                for pattern in date_patterns:
                    match = re.search(pattern, date_text)
                    if match:
                        if len(match.groups()) == 3:
                            if pattern.endswith(r"(\d{4})"):
                                # MM/DD/YYYY æ ¼å¼
                                month, day, year = match.groups()
                                return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
                            else:
                                # YYYY-MM-DD æˆ– YYYY.MM.DD æ ¼å¼
                                year, month, day = match.groups()
                                return f"{year}-{month}-{day}"
                        else:
                            # ä»…å¹´ä»½
                            year = match.group(1)
                            return f"{year}-01-01"
        
        current_year = datetime.now().year
        return f"{current_year}-01-01"
    
    def _extract_duration(self, soup: BeautifulSoup) -> str:
        """ä»é¡µé¢æå–è§†é¢‘æ—¶é•¿ã€‚
        
        æ ¼å¼ï¼šåˆ†é’Ÿæ•°ï¼ˆå¦‚ï¼š37ï¼‰
        æ”¯æŒHH:MM:SSæˆ–MM:SSæ ¼å¼è‡ªåŠ¨è½¬æ¢
        """
        duration_selectors = [
            ".duration",
            ".runtime",
            ".time",
            "[class*='duration']",
            "[class*='time']"
        ]
        
        for selector in duration_selectors:
            duration_elem = soup.select_one(selector)
            if duration_elem:
                duration_text = duration_elem.get_text().strip()
                # å°†HH:MM:SSæˆ–MM:SSè½¬æ¢ä¸ºæ€»åˆ†é’Ÿæ•°
                time_match = re.search(r"(?:(\d+):)?(\d+):(\d+)", duration_text)
                if time_match:
                    hours, minutes, seconds = time_match.groups()
                    hours = int(hours) if hours else 0
                    minutes = int(minutes)
                    seconds = int(seconds)
                    total_minutes = hours * 60 + minutes + (seconds / 60)
                    return str(int(total_minutes))
        
        return "30"  # è§†é¢‘é»˜è®¤30åˆ†é’Ÿ
    
    def _extract_maker(self, soup: BeautifulSoup) -> str:
        """ä»é¡µé¢æå–åˆ¶ä½œå•†ä¿¡æ¯ã€‚
        
        å¯è®¾ç½®çš„å€¼ï¼š
        - G@MESï¼ˆå¦‚RML4001æ ·æœ¬ä¸­çš„åˆ¶ä½œå•†ï¼‰
        - å…¶ä»–æˆäººè§†é¢‘åˆ¶ä½œå•†åç§°
        """
        maker_selectors = [
            ".maker",
            ".director",
            ".producer",
            "[class*='maker']",
            "[class*='director']"
        ]
        
        for selector in maker_selectors:
            maker_elem = soup.select_one(selector)
            if maker_elem:
                return maker_elem.get_text().strip()
        
        return "æœªçŸ¥åˆ¶ä½œå•†"
    
    def _extract_label(self, soup: BeautifulSoup) -> str:
        """ä»é¡µé¢æå–å‚ç‰Œ/åˆ¶ç‰‡å‚ä¿¡æ¯ã€‚
        
        å¯è®¾ç½®çš„å€¼ï¼š
        - åˆ¶ç‰‡å‚åç§°
        - å‘è¡Œå•†åç§°
        - é»˜è®¤ç©ºï¼ˆå¦‚æœæœªæ‰¾åˆ°ï¼‰
        """
        label_selectors = [
            ".label",
            ".studio",
            ".publisher",
            "[class*='label']",
            "[class*='studio']"
        ]
        
        for selector in label_selectors:
            label_elem = soup.select_one(selector)
            if label_elem:
                return label_elem.get_text().strip()
        
        return ""
    
    def _extract_artwork(self, soup: BeautifulSoup) -> str:
        """ä»é¡µé¢æå–å°é¢å›¾ç‰‡ã€‚
        
        ç”¨äºposterå­—æ®µï¼Œä»…ç”¨äºç”Ÿæˆå°é¢ï¼Œä¸åœ¨NFOä¸­è¾“å‡ºã€‚
        
        å¯è®¾ç½®çš„å€¼ï¼š
        - å®Œæ•´çš„å›¾ç‰‡URL
        - ç›¸å¯¹è·¯å¾„ï¼ˆä¼šè‡ªåŠ¨è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼‰
        """
        img_selectors = [
            ".poster img",
            ".cover img",
            ".thumbnail img",
            ".preview img",
            "img[class*='cover']",
            "img[class*='poster']",
            "img[class*='thumb']"
        ]
        
        for selector in img_selectors:
            img_elem = soup.select_one(selector)
            if img_elem:
                src = img_elem.get('src') or img_elem.get('data-src')
                if src:
                    return src if src.startswith('http') else f"https:{src}"
        
        return ""
    
    def _extract_series(self, soup: BeautifulSoup) -> str:
        """ä»é¡µé¢æå–ç³»åˆ—åç§°ã€‚
        
        å¯è®¾ç½®çš„å€¼ï¼š
        - ç³»åˆ—åç§°ï¼ˆå¦‚ï¼šãƒªãƒ¼ãƒãƒ³ãšãƒ©ãƒ–4ï¼‰
        - ä½œå“é›†åˆåç§°
        - é»˜è®¤ç©ºï¼ˆå¦‚æœæœªæ‰¾åˆ°ï¼‰
        """
        series_selectors = [
            ".series",
            ".collection",
            "[class*='series']",
            "[class*='collection']"
        ]
        
        for selector in series_selectors:
            series_elem = soup.select_one(selector)
            if series_elem:
                return series_elem.get_text().strip()
        
        return ""
    
    def get_template_for_site(self) -> str:
        """è·å–é€‚åˆtrance videoç½‘ç«™çš„æ¨¡æ¿ã€‚
        
        è¿”å›æˆäººå†…å®¹ä¸“ç”¨æ¨¡æ¿ã€‚
        """
        return "adult"