import black

import requests
from bs4 import BeautifulSoup
import xml.etree.ElementTree as ET
from xml.dom import minidom
import re
import json
import time
from datetime import datetime


class CkDownloadNfoGenerator:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
        )
        self.movie_data = {}

    def extract_info_from_url(self, url):
        match = re.search(r"product/detail/(\d+)", url)
        if match:
            return match.group(1)
        return None

    def scrape_movie_info(self, url):
        print("ğŸš€ å¼€å§‹å°è¯•è·å–å½±ç‰‡ä¿¡æ¯...")
        try:
            response = self.session.get(url, timeout=10)
            response.encoding = "utf-8"
            if response.status_code != 200:
                print(f"âŒ è®¿é—®å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return False
            soup = BeautifulSoup(response.text, "html.parser")
            title_elem = soup.select_one("div#Contents h3")
            title = title_elem.get_text().strip() if title_elem else "æœªçŸ¥æ ‡é¢˜"
            
            product_number = self.extract_product_number(soup)
            title = f"{product_number} {title}".strip()
            
            self.movie_data = {
                "title": title,
                "originaltitle": title,
                "sorttitle": self.generate_sort_title(title),
                "product_id": self.extract_info_from_url(url) or "26966",
                "year": self.extract_year_from_page(soup),
                "plot": self.extract_plot(soup),
                "outline": self.extract_premiered(soup),
                "genres": self.extract_tags(soup),
                "actors": self.extract_actors(soup),
                "director": self.extract_director(soup),
                "runtime": self.extract_runtime(soup),
                "premiered": "",
                "thumb": "",
                "fanart": "",
            }
            print("âœ… åŸºæœ¬ä¿¡æ¯è·å–å®Œæˆ")
            return True
        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            return False

    def extract_product_number(self, soup):
        num_td = soup.find("th", string="ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒŠãƒ³ãƒãƒ¼")
        if num_td and num_td.find_next("td"):
            return num_td.find_next("td").get_text(strip=True)
        return ""

    def extract_tags(self, soup):
        tags = []
        category_div = soup.select_one("div.prod_category")
        if category_div:
            for a in category_div.select("a"):
                text = a.get_text(strip=True)
                if text:
                    tags.append(text)
        return tags

    def generate_sort_title(self, title):
        if not title:
            return "Unknown"
        return "".join([word[0].upper() for word in title.split() if word])

    def extract_year_from_page(self, soup):
        premiered_date = self.extract_premiered(soup)
        if premiered_date:
            return premiered_date.split("-")[0]
        return str(datetime.now().year)

    def extract_plot(self, soup):
        intro_div = soup.select_one("div.intro_text")

        if intro_div:
            # æå–æ‰€æœ‰æ®µè½æ–‡æœ¬
            paragraphs = []
        p_elements = intro_div.find_all("p")

        for p in p_elements:
            text = p.get_text().strip()
            if text:
                # å¤„ç†æ¢è¡Œç¬¦ï¼Œå°†<br>è½¬æ¢ä¸ºæ¢è¡Œ
                br_elements = p.find_all("br")
                if br_elements:
                    # ä½¿ç”¨BeautifulSoupçš„get_textæ–¹æ³•å¤„ç†æ¢è¡Œ
                    text = p.get_text("\n", strip=True)
                paragraphs.append(text)

        if paragraphs:
            # åˆå¹¶æ‰€æœ‰æ®µè½ï¼Œç”¨ä¸¤ä¸ªæ¢è¡Œç¬¦åˆ†éš”
            return "\n\n".join(paragraphs)

        # å¤‡ç”¨é€‰æ‹©å™¨
        return "æš‚æ— å‰§æƒ…ç®€ä»‹"

    def extract_premiered(self, soup):
        date_div = soup.select_one("div.add_info div.date")
        if date_div:
            date_text = date_div.get_text().strip()
            date_match = re.search(r"(\d{4})\.(\d{2})\.(\d{2})", date_text)
            if date_match:
                year, month, day = date_match.groups()
                return f"{year}-{month}-{day}"
        current_year = datetime.now().year
        return f"{current_year}-01-01"

    def extract_genres(self, soup):
        return ["å‰§æƒ…", "çˆ±æƒ…"]

    def extract_actors(self, soup):
        return [{"name": "æ¼”å‘˜1", "role": "ä¸»è§’"}, {"name": "æ¼”å‘˜2", "role": "é…è§’"}]

    def extract_director(self, soup):
        return "çŸ¥åå¯¼æ¼”"

    def extract_runtime(self, soup):
        return "120"

    def manual_input_correction(self):
        print("\n" + "=" * 50)
        print("ğŸ“ è¯·æ£€æŸ¥å¹¶ä¿®æ­£ä»¥ä¸‹ä¿¡æ¯")
        print("=" * 50)
        current_data = self.movie_data.copy()
        print(f"å½“å‰æ ‡é¢˜: {current_data['title']}")
        new_title = input("è¯·è¾“å…¥ä¿®æ­£åçš„æ ‡é¢˜(ç›´æ¥å›è½¦ä¿æŒå½“å‰): ").strip()
        if new_title:
            current_data["title"] = new_title
        print(f"\nå½“å‰å¹´ä»½: {current_data['year']}")
        new_year = input("è¯·è¾“å…¥ä¿®æ­£åçš„å¹´ä»½: ").strip()
        if new_year:
            current_data["year"] = new_year
        print(f"\nå½“å‰å‰§æƒ…ç®€ä»‹:\n{current_data['plot']}")
        new_plot = input("è¯·è¾“å…¥ä¿®æ­£åçš„å‰§æƒ…ç®€ä»‹(ç›´æ¥å›è½¦ä¿æŒå½“å‰):\n").strip()
        if new_plot:
            current_data["plot"] = new_plot
        print(f"\nå½“å‰å¯¼æ¼”: {current_data['director']}")
        new_director = input("è¯·è¾“å…¥ä¿®æ­£åçš„å¯¼æ¼”: ").strip()
        if new_director:
            current_data["director"] = new_director
        print(f"\nå½“å‰ç‰‡é•¿: {current_data['runtime']}åˆ†é’Ÿ")
        new_runtime = input("è¯·è¾“å…¥ä¿®æ­£åçš„ç‰‡é•¿: ").strip()
        if new_runtime:
            current_data["runtime"] = new_runtime
        print(f"\nå½“å‰ä¸Šæ˜ æ—¥æœŸ: {current_data['premiered'] or 'æœªè®¾ç½®'}")
        new_premiered = input("è¯·è¾“å…¥ä¸Šæ˜ æ—¥æœŸ(YYYY-MM-DD): ").strip()
        if new_premiered:
            current_data["premiered"] = new_premiered
        print(f"\nå½“å‰æµ·æŠ¥URL: {current_data['thumb'] or 'æœªè®¾ç½®'}")
        new_thumb = input("è¯·è¾“å…¥æµ·æŠ¥å›¾ç‰‡URL: ").strip()
        if new_thumb:
            current_data["thumb"] = new_thumb
        print(f"\nå½“å‰èƒŒæ™¯å›¾URL: {current_data['fanart'] or 'æœªè®¾ç½®'}")
        new_fanart = input("è¯·è¾“å…¥èƒŒæ™¯å›¾URL: ").strip()
        if new_fanart:
            current_data["fanart"] = new_fanart
        print(f"\nå½“å‰æ¼”å‘˜ä¿¡æ¯:")
        for i, actor in enumerate(current_data["actors"]):
            print(f"  {i+1}. {actor['name']} é¥°æ¼” {actor['role']}")
        modify_actors = input("\næ˜¯å¦ä¿®æ”¹æ¼”å‘˜ä¿¡æ¯? (y/n): ").lower()
        if modify_actors == "y":
            current_data["actors"] = []
            print("è¯·è¾“å…¥æ¼”å‘˜ä¿¡æ¯(è¾“å…¥'done'ç»“æŸ):")
            while True:
                name = input("æ¼”å‘˜å§“å: ").strip()
                if name.lower() == "done":
                    break
                role = input("æ‰®æ¼”è§’è‰²: ").strip()
                current_data["actors"].append({"name": name, "role": role})
                print("---")
        print(f"\nå½“å‰å½±ç‰‡é£æ ¼: {', '.join(current_data['genres'])}")
        modify_genres = input("æ˜¯å¦ä¿®æ”¹é£æ ¼ä¿¡æ¯? (y/n): ").lower()
        if modify_genres == "y":
            current_data["genres"] = []
            print("è¯·è¾“å…¥å½±ç‰‡é£æ ¼(è¾“å…¥'done'ç»“æŸ):")
            while True:
                genre = input("é£æ ¼: ").strip()
                if genre.lower() == "done":
                    break
                current_data["genres"].append(genre)
        self.movie_data = current_data
        return True

    def create_nfo_file(self):
        if not self.movie_data:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„å½±ç‰‡æ•°æ®")
            return False
        movie = ET.Element("movie")
        ET.SubElement(movie, "title").text = self.movie_data["title"]
        ET.SubElement(movie, "originaltitle").text = self.movie_data["originaltitle"]
        ET.SubElement(movie, "sorttitle").text = self.movie_data["sorttitle"]
        ratings = ET.SubElement(movie, "ratings")
        rating = ET.SubElement(
            ratings, "rating", name="default", max="10", default="true"
        )
        ET.SubElement(rating, "value").text = "7.5"
        ET.SubElement(rating, "votes").text = "1000"
        ET.SubElement(movie, "userrating").text = "0"
        ET.SubElement(movie, "top250").text = "0"
        ET.SubElement(movie, "year").text = self.movie_data["year"]
        ET.SubElement(movie, "plot").text = self.movie_data["plot"]
        ET.SubElement(movie, "outline").text = self.movie_data["outline"]
        ET.SubElement(movie, "tagline").text = ""
        ET.SubElement(movie, "runtime").text = self.movie_data["runtime"]
        if self.movie_data["thumb"]:
            ET.SubElement(movie, "thumb", aspect="poster").text = self.movie_data[
                "thumb"
            ]
        if self.movie_data["fanart"]:
            fanart = ET.SubElement(movie, "fanart")
            ET.SubElement(fanart, "thumb").text = self.movie_data["fanart"]
        ET.SubElement(movie, "mpaa").text = "TV-MA"
        ET.SubElement(movie, "premiered").text = self.movie_data.get(
            "premiered", "2023-01-01"
        )
        ET.SubElement(movie, "releasedate").text = self.movie_data.get(
            "premiered", "2023-01-01"
        )
        ET.SubElement(movie, "certification").text = "CN-18"
        product_id = self.movie_data.get("product_id", "26966")
        ET.SubElement(movie, "id").text = f"ck-download-{product_id}"
        ET.SubElement(movie, "uniqueid", type="ck-download", default="true").text = (
            product_id
        )
        for genre in self.movie_data["genres"]:
            ET.SubElement(movie, "tag").text = genre
        ET.SubElement(movie, "studio").text = "CK-Download"
        ET.SubElement(movie, "trailer").text = ""
        for i, actor in enumerate(self.movie_data["actors"]):
            actor_elem = ET.SubElement(movie, "actor")
            ET.SubElement(actor_elem, "name").text = actor["name"]
            ET.SubElement(actor_elem, "role").text = actor["role"]
            ET.SubElement(actor_elem, "order").text = str(i)
            ET.SubElement(actor_elem, "thumb").text = ""
        ET.SubElement(movie, "director").text = self.movie_data["director"]
        ET.SubElement(movie, "credits").text = self.movie_data["director"]
        ET.SubElement(movie, "set").text = ""
        ET.SubElement(movie, "country").text = "ä¸­å›½"
        ET.SubElement(movie, "tag").text = "ck-download"
        ET.SubElement(movie, "tag").text = "å›½äº§"
        rough_string = ET.tostring(movie, "utf-8")
        reparsed = minidom.parseString(rough_string)
        pretty_xml = reparsed.toprettyxml(indent="  ", encoding="utf-8")
        filename = f"{self.movie_data['title']}.nfo"
        with open(filename, "wb") as f:
            f.write(pretty_xml)
        print(f"\nâœ… NFOæ–‡ä»¶å·²ç”Ÿæˆ: {filename}")
        return filename

    def run(self):
        print("ğŸ¬ CK-Download NFO æ–‡ä»¶ç”Ÿæˆå™¨")
        print("=" * 40)
        url = input("è¯·è¾“å…¥å½±ç‰‡URL: ").strip()
        if not url:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„URL")
            return
        success = self.scrape_movie_info(url)
        if not success:
            print("âš ï¸  è‡ªåŠ¨çˆ¬å–å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ä¿¡æ¯")
            self.movie_data = {
                "title": "",
                "originaltitle": "",
                "sorttitle": "",
                "product_id": self.extract_info_from_url(url) or "26966",
                "year": "2023",
                "plot": "",
                "outline": "",
                "genres": [],
                "actors": [],
                "director": "",
                "runtime": "120",
                "premiered": "",
                "thumb": "",
                "fanart": "",
            }
        self.manual_input_correction()
        nfo_file = self.create_nfo_file()
        if nfo_file:
            print(f"\nğŸ‰ å®Œæˆï¼è¯·å°† '{nfo_file}' ä¸è§†é¢‘æ–‡ä»¶æ”¾åœ¨åŒä¸€ç›®å½•ä¸‹")
        print("ğŸ’¡ æç¤º: ç¡®ä¿NFOæ–‡ä»¶ä¸è§†é¢‘æ–‡ä»¶ä¸»æ–‡ä»¶åç›¸åŒ")


if __name__ == "__main__":
    generator = CkDownloadNfoGenerator()
    generator.run()
